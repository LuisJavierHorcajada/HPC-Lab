import time
import cv2
import numpy as np
import argparse
from mpi4py import MPI

def argparser():
    parser = argparse.ArgumentParser()
    parser.add_argument("-k", "--kmeans", dest="K", type=int, required=True, help="Kmeans size")
    parser.add_argument("-i", "--iterations", dest="I", type=int, required=True, help="Max Iterations")
    args = parser.parse_args()
    K = args.K
    max_iterations = args.I
    return K, max_iterations

def kmeans(data, K, max_iterations):
    # Se inicializan los centroides aleatoriamente eligiendo K puntos de los datos
    indices = np.random.choice(data.shape[0], K, replace=False)
    centroids = data[indices]

    # Copia de centroides para su posterior comparación
    prev_centroids = centroids.copy()

    tolerance = 0.2
    for i in range(max_iterations):
        # Se asignan los datos a cada centroide según su distancia
        distances = np.linalg.norm(data[:, np.newaxis] - centroids, axis=2)
        labels = np.argmin(distances, axis=1)

        # Se actualiza la posición de cada centroide en función de la cantidad de datos de cada uno
        centroids = np.zeros((K, data.shape[1]))
        for j in range(K):
            cluster_points = data[labels == j]
            if len(cluster_points) > 0:
                centroids[j] = np.mean(cluster_points, axis=0)

        # Se comprueba la distancia con los centroides anteriores
        if np.linalg.norm(centroids - prev_centroids) < tolerance:
            break

        prev_centroids = centroids.copy()

    return labels, centroids

def run_kmeans(data, K, max_iterations):
    print(f'\nEmpezando kmeans con {K} clusters desde [PROCESO {rank}]')
    start_time = time.time()
    labels, centroids = kmeans(data, K, max_iterations)
    end_time = time.time()
    execution_time = end_time - start_time
    return labels, centroids, execution_time

if __name__ == "__main__":
    FIXED_SIZE = 783640
    comm = MPI.COMM_WORLD
    rank = comm.Get_rank()
    size = comm.Get_size()
    K, max_iterations = argparser()

    # Leer los datos de entrada.
    if rank == 0:
        print(f'\nEjecutando con {size} procesos')
        # Read data from file on root process
        data = np.loadtxt('pavia.txt', delimiter=',')

        # Reshape the data into chunks matching the number of MPI processes
        chunk_size = len(data) // size
        scattered_data = []
        for i in range(size):
            if i == size - 1:
                scattered_data.append(data[i * chunk_size :])
            else:
                scattered_data.append(data[i * chunk_size : (i + 1) * chunk_size])

    else:
        scattered_data = None
        
    data_scattered = comm.scatter(scattered_data, root=0)

    # Convertir a un array NumPy
    data_array = np.array(data_scattered)

    print("Data array ", data_array.shape)

    # Reorganizar los valores para adaptar a la entrada del kmeans
    # Son 1096x715 pixeles, cada uno con 102 componentes.
    matrix = np.reshape(data_array, (len(data_array),102))

    # Los puntos de entrada para la primitiva kmeans deben ser de tipo punto flotante
    pixels = matrix.astype(np.float32)

    print("pixels array ", pixels.shape)

    labels,centroids, execution_time=run_kmeans(pixels, K, max_iterations)
    print(f'\n[PROCESO {rank}] Tiempo final: {str(execution_time)} segundos')
    print("labels array ", labels.shape)
    print("centers array ", centroids.shape)

    all_labels = comm.gather(labels, root=0)
    all_centroids = comm.gather(centroids, root=0)
    all_times = comm.gather(execution_time, root=0)

    if rank == 0:
        # Merge results if necessary
        merged_labels = np.concatenate(all_labels)
        merged_centroids = np.concatenate(all_centroids)
        total_time = max(all_times)
        print(f"\nEl tiempo de ejecución máximo ha sido de: {str(total_time)} segundos")

        # Reorganize the merged_labels into image shape
        cluster_map = np.reshape(merged_labels, (715, 1096)).astype(np.uint8)

        # Map colors to clusters
        colors = [
            (0, 0, 255),   # Red
            (0, 255, 0),   # Green
            (255, 0, 0),   # Blue
            (255, 255, 0), # Yellow
            (255, 0, 255), # Magenta
            (0, 255, 255), # Cyan
            (255, 255, 255), # White
            (0, 0, 0),     # Black
            (128, 128, 128), # Gray
            (64, 64, 64)   # Gray
        ]
        color_map_array = np.array(colors)

        # Assign colors to each pixel based on the cluster labels
        result_image = np.zeros((1096, 715, 3), dtype=np.uint8)
        for i in range(result_image.shape[0]):
            for j in range(result_image.shape[1]):
                result_image[i, j] = color_map_array[cluster_map[j, i]]

        # Show the clustered image
        cv2.imshow('Cluster image', result_image)
        cv2.imwrite("paviakmeans_mpi.jpg", result_image)
        cv2.waitKey(0)
        cv2.destroyAllWindows()
